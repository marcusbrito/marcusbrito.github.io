= Processamento Digital de Imagem
Marcus Brito <mvobrito@gmail.com>
:toc: left
:numbered:
:source-highlighter: pygments
:stem:

== Sobre

Esse espaço tem como objetivo expor os projetos e exercícios da matéria de Processamento Digital de Imagem.

== Primeira Unidade
=== Negativo
==== Objetivo

A ideia do programa é receber do usuário as coordenadas de dois pontos e, em seguida, exibir a imagem(que foi inicializada junto com o programa), invertendo a cor dos pixels da região limitada pelos pontos.

==== Código

[source,cpp]
.regions.cpp
----
include::regions.cpp[]
----

==== Análise

* O programa inicia lendo a imagem:

.dead.png
image::dead.png[]

* Em seguida, recebe os pontos do usuário, e verifica se eles estão dentro dos limites da imagem:

[source,cpp]
----
if(p1[0]<0 || p1[1]<0 || p2[0]<0 || p2[1]<0 || p1[0]> image.size().height || p1[1]> image.size().width || p2[0]> image.size().height || p2[1]> image.size().width){
      flag = 1;
      cout << "Coodenadas invalidas. Digite novamente:" << endl;
    }
----

* Então, um loop(for) percorre a região limitada pelos pontos invertendo o valor dos pixels a partir da operação "Cor negativa = 255 - Cor original":

[source,cpp]
----
for(int i= p1[0];i<=p2[0];i++){
    for(int j=p1[1];j<=p2[1];j++){
      image.at<uchar>(i,j) = 255 - image.at<uchar>(i,j);
    }
  }
----

* Por fim, exibe a imagem com o efeito aplicado:

.invertida.png
image::invertida.png[]

=== Troca de Regões
==== Objetivo

O objetivo do programa é trocar as posições dos "quadrantes" da imagem.

==== Código

[source,cpp]
.trocaregioes.cpp
----
include::trocaregioes.cpp[]
----

==== Análise

* Nesse caso, a imagem já é passado como parâmetro ao executarmos o programa no terminal:

.dead.png
image::dead.png[]

* Em seguida, uma segunda imagem "trocada" é criada, com o mesmo tamanho da imagem original:

[source,cpp]
----
Mat trocada(height, width, image.type());
----

* Então, "trocada" é preenchida com os quadrantes da imagem original, só que com suas posições invertidas. Esse processo é feito utilizando dois métodos da biblioteca OpenCV:
+
	Rect - Cria uma seleção retângular a partir das coordenadas e dimenssões passadas como parâmetro.
+
	copyTo - Copia o conteudo da primeira imagem par a segunda(Imagem1.copyTo(Imagem2)).

[source,cpp]
----
  image(Rect(0, 0, width/2, height/2)).copyTo(trocada(Rect(width/2, height/2, width/2, height/2)));
  
  image(Rect(0, height/2, width/2, height/2)).copyTo(trocada(Rect(width/2,0, width/2, height/2)));

  image(Rect(width/2,0,width/2,height/2)).copyTo(trocada(Rect(0,height/2, width/2, height/2)));

  image(Rect(width/2,height/2,width/2,height/2)).copyTo(trocada(Rect(0,0, width/2, height/2)));
----

* Por fim, exibe a imagem com o efeito aplicado:

.trocada.png
image::trocada.png[]

=== Contador de Bolhas
==== Objetivo

O objetivo do código é efetuar a contagem de bolhas presentes na imagem, identificando se elas possuem ou não buracos.

==== Código

[source,cpp]
.labeling.cpp
----
include::labeling.cpp[]
----

==== Análise
* Inicialmente, o programa abre a imagem:

.bolhas.png
image::bolhas.png[]

* Em seguida, para retirar as bolhas que tocam as bordas(já que não é possível saber se elas possuem bolhas ou não), um loop percorre as bordas e, caso encontre alguma pixel com valor 255(branco), ele executa a função seedfill, que preenche a bolha com a cor preta:

[source,cpp]
----
for(int i=0; i<height; i++)
{
    if(image.at<uchar>(i,0) == 255)
    {
      p.x=0;
      p.y=i;
      seedfill(image,p,0);
    }
    if(image.at<uchar>(i,width-1) == 255)
    {
      p.x=width-1;
      p.y=i;
      seedfill(image,p,0);
    }
  }
  for(int j=0; j<width; j++) 
  {
    if(image.at<uchar>(0,j) == 255)
    {
      p.x=j;
      p.y=0;
      seedfill(image,p,0);
    }
    if(image.at<uchar>(height -1,j) == 255)
    {
      p.x=j;
      p.y=height-1;
      seedfill(image,p,0);
    }
}
----

* A função seedfild, por sua vez, recebe três parâmetros: um tipo Mat(a imagem), um tipo CvPoint(o ponto inicial) e um tipo unsigned char(a cor com qual deseja-se preencher a região). Seu funcionamento ocorre a partir de um tipo Pilha(stack):
+
- Inicia-se a pilha com a posição passada como parâmetro;
+
- Enquanto a pilha não estiver vazia, executa-se o processo:
+
	- Retira-se o elemento da pilha(o do "topo", como é característico da pilha);
+
	- Verifica se os pontos vizinhos a ele(4-vizinhos) são da mesma cor dele e, caso sejam, são colocados na pilha.
+
	- "Pinta" o ponto atual com a cor passada por parâmetro;
+
[source,cpp]
----
void seedfill(Mat image, CvPoint p, unsigned char cor){
  stack<CvPoint> pilha;
  unsigned char cor_atual;
  CvPoint aux1,aux2,aux3,aux4,atual;

  pilha.push(p);
  cor_atual = image.at<uchar>(p.y,p.x);
  while(!pilha.empty()){
    atual = pilha.top();
    pilha.pop();
    
    if(image.at<uchar>(atual.y + 1,atual.x) == cor_atual && atual.y < image.cols - 1 ){

    aux1.x = atual.x;
    aux1.y = atual.y + 1;
    pilha.push(aux1);
    
    }
    if(image.at<uchar>(atual.y - 1,atual.x) == cor_atual && atual.y > 0){

    aux2.x = atual.x;
    aux2.y = atual.y - 1;
    pilha.push(aux2);

    
    }
    if(image.at<uchar>(atual.y,atual.x + 1) == cor_atual && atual.x < image.rows - 1 ){

    aux3.x = atual.x + 1;
    aux3.y = atual.y;
    pilha.push(aux3);

    
    }
    if(image.at<uchar>(atual.y,atual.x - 1) == cor_atual && atual.x > 0){

    aux4.x = atual.x - 1;
    aux4.y = atual.y;
    pilha.push(aux4);
    }
  image.at<uchar>(atual.y,atual.x) = cor;  
  }
}
----
* Inicia-se então, a busca pelas bolhas. Primeiramente, executa-se um seedfill no ponto(0,0), com o objetivo de preecher o plano de fundo com a a "cor" 254, de forma que é possível diferenciar a cor do plano de fundo da cor dos buracos:

[source,cpp]
----
p.x=0;
  p.y=0;
  seedfill(image,p,254);
----

* Em seguida, a imagem é varrida a procura de um píxel com valor 0, cujo o ponto anterior possui valor 255, ou seja, um buraco. O contador comf(número de bolhas com furos) é incrementado e, em seguida, executa-se o seedfill no ponto anterior, de forma que a bolha é preenchida com o valor 1(para que essa mesma bolha não seja levada em conta novamente). Ao final desse processo, as bolhas com furos já foram contabilizadas.

[source,cpp]
----
for(int i=0; i<height; i++)
  {
    for(int j=0; j<width; j++)
    {
      if(image.at<uchar>(i,j) == 0 && image.at<uchar>(i,j-1) == 255 )
      {
        // achou um objeto
        comf++;
        p.x=j;
        p.y=i;

        p1.x=j-1;
        p1.y=i;
        seedfill(image,p1,1);
      }
    }
  }
----
* Então, percorre-se novamente a imagem, procurando agora pontos com valor 255, ou seja, as bolhas(sem furos) restantes. Ao encontrá-las, execulta-se o seedfill e incrementa-se o contador semf(número de bolhas sem furos). Ao final desse processo, todas as bolhas já foram contadas.

[source,cpp]
----
for(int i=0; i<height; i++){
    for(int j=0; j<width; j++){
      if(image.at<uchar>(i,j) == 255){
        // achou um objeto
        semf++;
        p.x=j;
        p.y=i;
        seedfill(image,p,semf);
      }
    }
  }
----
* Por fim, é exibida a imagem após as alterações feitas pelo seedfill, assim como o número de bolhas com e sem furos:

.labeling.png
image::labeling.png[]

----
Bolhas com furos: 7
Bolhas sem furos: 14
----

=== Equalização de Histograma

==== Objetivo

O objetivo desse programa é efetuar a captura de imagens em tempo real(vídeo) e equalizar os quadros obtidos, de forma que o contraste da imagem é aumentado.

==== Código

[source,cpp]
.equalize.cpp
----
include::equalize.cpp[]
----

==== Análise

* Dessa vez nós utilizamos a webcam do computador. O OpenCV possui uma ferramenta que permite acessar facilmente as cameras conectadas ao computador:

[source,cpp]
----
VideoCapture cap;
cap.open(0);
----

* Em seguida, inicia-se um loop(while) que só termina quando o usuário digitar alguma tecla. Utilizando a função "cap", a câmera do computador capitura quadros e armazena na variavel "image". Ela é então convertida para tons de cinza, e depois tem seu histograma equalizado por meio da função "equalizeHist".

[source,cpp]
----
while(1){
    cap >> image;
    cvtColor(image, original, CV_BGR2GRAY);
    
    equalizeHist( original, equalizada );
    
    imshow("Original", original);
    imshow("Equalizada", equalizada);
    if(waitKey(30)>=0) break;
  }
----
* O processo de equalização ocorre da seguinte forma:

- Obtem-se o histograma da imagem;
- Calcula-se o histograma acumulado;
- Normatiza-se o histograma acumulado(dividindo todos os termos pelo maior);
- Multiplica-se os valores normalizados pelo maior valor que deseja-se representar(geralmente 255);
- Dessa forma, obtem-se os valores equalizados para os pixels.

* Por fim, a imagem original e a imagem equalizada são exibidas na tela.

.original.png
image::original.png[]

.equalizada.png
image::equalizada.png[]

* É visível que houve um significativo aumento no contraste.

=== Detecção de movimento
==== Objetivo

A ideia do programa é avisar quando ocorrer algum movimento na cena capturada através de uma dispositivo de gravação.

==== Código

[source,cpp]
.detector_de_movimento.cpp
----
include::detector_de_movimento.cpp[]
----

==== Análise

* Para efetuar a detecção de movimento, faremos uso do histograma da imagem. Inicialmente, utilizamos a câmera do computador para filmar o cenário, enquanto o usuário não aperta alguma tecla. Cada quadro obtido é separado em três planos, ou seja, suas componentes R,G e B são armazenadas no vetor de Mat(planes):

[source,cpp]
----
cap >> image1;
split (image1, planes1);
----

* É feito, então, o cálculo do histograma de uma das componente da imagem, por meio da função "calcHist"(Foi utilizada a componente de cor azul(planes1[2]) para o cálculo, pois mostrou ser a mais adequada para detectar movimento):

[source,cpp]
----
calcHist(&planes1[2], 1, 0, Mat(), hist1, 1,&nbins, &histrange,uniform, acummulate);
----

* Esse processo ocorre tanto com o quadro atual(image1), quanto com o quadro anterior(image). Com isso, podemos comparar os dois histogramas: Se houver uma diferença muito grande entre eles, houve uma alguma alteração no cenário, uma característica de movimento na cena. A comparação entre os histogramas é feita a partir da função "norm", que cálcula o somtório dos módulos das diferenças entre os valores dos dois histogramas:

[source,cpp]
----
valor = norm(hist, hist1, NORM_L2, Mat() );
----

* O valor armazenado em "valor" representa a diferença entre os dois histogramas. O programa verifica "valor" e, caso seja maior que 8000(valor obtido experimentalmente), quer dizer que houve algum movimento na tela. Nesse caso, é exibido um aviso:

[source,cpp]
----
if(valor>8000)
    printf("MOVIMENTO DETECTADO - %f\n",valor );
----

=== Filtro Laplaciano do Gaussiano
==== Objetivo

O objetivo era modificar o programa "filtroespacial" apresentado pelo professor para adicionar a função de utilizar o filtro laplaciano por cima do filtro gaussiano.

==== Código

[source,cpp]
.filtroespacial2.cpp
----
include::filtroespacial2.cpp[]
----

==== Análise

* O filtro laplaciano simula o operador matemático laplaciano, e, no caso da imagem, acaba medindo o quanto um ponto se destaca dos outros ao seu redor. Numa imagem com ruído, aparecem pontos claros em regiões escuras, assim como pontos escuros em regiões claras. Nessa situação, a aplicação puramente do filtro laplaciano não seria muito satisfatória, pois todos esses pontos de ruídos seriam extremamente evidenciados no resultado final, produzindo uma imagem de baixa qualidade. 

* Uma das soluções para isso é tentar diminuir a intensidade desse pontos isolados de ruído. Uma forma de fazer isso é aplicando o filtro gaussinao. Seu efeito de difusão/borramento, que em outras situações pode paracer indesejado, resolve o porblema dos pontos isolados, pois "mistura" um pouco o ponto com os outros ao seu redor(é como se o ponto isolado fosse distribuido). 

* A única diferença no código em si é que foi adicionada uma nova opção: "laplgauss". Ao ser verificado que o usuário escolheu a mesma, o progama aplica o filtro gaussiano e armazena a imagem em uma Matriz auxiliar. Em seguida, sobre essa matriz auxiliar é aplicado o filtro laplaciano, resultando na imagem final:

[source,cpp]
----
if (aux == 0)
{
	filter2D(frame32f, frameFiltered, frame32f.depth(), mask, Point(1,1), 0);
}
else{
   mask = Mat(3, 3, CV_32F, gauss);
   scaleAdd(mask, 1/16.0, Mat::zeros(3,3,CV_32F), mask1);
   mask = mask1;
   filter2D(frame32f, frameAux, frame32f.depth(), mask, Point(1,1), 0);
   mask = Mat(3, 3, CV_32F, laplacian);
   filter2D(frameAux, frameFiltered, frameAux.depth(), mask, Point(1,1), 0);
}
----
* O efeito pode ser observado na imagens abaixo:

.Imagem Original
image::original1.png[]

.Apenas com filtro laplaciano
image::lapl.png[]

.Filtros gaussiano e laplaciano
image::laplgauss.png[]

* Fica claro que, ao aplicarmos a combinação dos dois filtros, a nitidez da imagem é bem maior.

=== Tilt Shift
==== Objetivo

O objetivo dessa atividade era simular o efeito chamado _tiltshift_, geralmente feito com lentes epeciais, mas realizando o processo em software a partir das técnicas de processamento de imagem estudadas até agora.

[source,cpp]
.tiltshift.cpp
----
include::tiltshift.cpp[]
----

==== Análise

* O efeito _tiltshift_ é gerado por uma inclinação entre o plano de foco(plano da cena que deseja-se fotografar) e o plano da projeção(plano do sensor no qual a luz incide). Para criar esse feito em "hardware", são utilizadas lentes especiais, geralmente muito caras. Entretanto, é possível simular o mesmo resultado a partir de técnicas de processamento de imagem demostradas a seguir.

* A ideia é pegar a imagem original e somá-la com ela própia borrada, com as proporções adequadas para simular o efeito.

* Inicialmente, é realizado o borramento da imagem:

[source,cpp]
----
float media[] = {1,1,1,
           1,1,1,
           1,1,1};
  Mat mask(3,3,CV_32F), mask1;

  mask = Mat(3, 3, CV_32F, media);
  scaleAdd(mask, 1/9.0, Mat::zeros(3,3,CV_32F), mask1);
  mask = mask1;

  for (int i = 0; i < 40; ++i)
  {
    filter2D(original, borrada, original.depth(), mask, Point(1,1), 0);
  }
----

* Foi utilizado o filtro da média, que gera o borramento. Para que efeito fique bastante evidente, o efeito foi aplicado 40 vezes.

* A função utilizada para simular o "degradê" da foto normal para a foto borrada foi:

.Função
image::funcao.png[]
image::func.png[]

* No programa, ela foi simulada por: 

[source,cpp]
----
double calcAlpha(double x, double l1, double l2, double d){
  return 0.5*(tanh((x-l1)/d) - tanh((x-l2)/d));
}
----

* X representa a linha da imagem, L1 representa o limite superior em que a função vale 0.5, L2 o limite inferior, e D o decaimento da imagem(quanto maior o D, menor o decaimento).

* A partir dessa função, denominada alpha, pudemos realizar a soma da imagem original(multiplicada por alpha) com a imagem borrada(multiplicada por alpha -1):

[source,cpp]
----
void blend(int, void*){
 for (int i = 0; i < original.rows ; i++)
 {
   double alpha = calcAlpha(i,sup_slider,inf_slider,d_slider);
   addWeighted(original.row(i),alpha, borrada.row(i),1-alpha,0.0,final.row(i));
 }
 imshow("resultado", final);
}
----

* A função "addWeighted" efetua a soma das linhas da imagem "original" ponderada pelo fator alpha com as linhas  de "borrada" ponderada por 1 - alpha, e armazena o resultado em "final". 

* Para que o usuário pudesse selecionar os parâmetros, criamos _trackbars_. Uma para selecionar D, uma para L1 e outra para L2.

[source,cpp]
----
sprintf( TrackbarName, "Decaimento", d_max );
  createTrackbar( TrackbarName, "resultado",
          &d_slider,
          d_max,
          blend );
  blend(d_slider, 0 );
  
  sprintf( TrackbarName, "Limite superior", sup_max );
  createTrackbar( TrackbarName, "resultado",
          &sup_slider,
          sup_max,
          blend);
  blend(sup_slider, 0 );

  sprintf( TrackbarName, "Limite inferior", inf_max );
  createTrackbar( TrackbarName, "resultado",
          &inf_slider,
          inf_max,
          blend );
  blend(inf_slider, 0 );
----

* Sempre que o usuário altera algum valor, a função _blend_ é novamente chamada, os cálculos são feitos novamentes, e a nova imagem é exibida.

* Esse método provou-se bastante efetivo, permitindo produzir imagens com um efeito muito similar ao da lente especial:

.Função
image::tiltshift.png[]
image::vaticano.jpg[]

== Segunda Unidade
=== Filtro Homomórfico
==== Objetivo

O objetivo é criar um filtro homomófico, que serve para correção de fotos com iluminação excessiva(situação conhecida como _overexposuse_, ou sobreesposição). A filtragem é feita no domínio da frequência, e usa uma ferrementa matemática para filtrar apenas uma componente da imagem(iluminância). Os detralhes serão descutido ao logo da explicação do código.

==== Código

[source,cpp]
.homo.cpp
----
include::homo.cpp[]
----

==== Análise

  Como foi estudado, uma imagem é formada pelo produto da iluminância(quantidade de luz que atinge cada ponto) e reflectância(o quanto cada ponto reflete da luz que recebe):

  f(x,y) = i(x,y) * r(x,y)

  Como o objetivo do filtro homomórfico é corrigir a iluminação da imagem, precisamos de um filtro que atinja apenas a iluminância. Surge então o problema: como atingir apenas uma componente da imagem, atingindo minimamente a outra componente? Conseguimos a partir de uma artifício matemático. Se aplicarmos o logaritmo natural a ambos os lados da equação, obtemos: 

  z(x,y) = ln f(x,y) = ln i(x,y) + ln r(x,y)]

  Agora, as compontes estão se somando, e não multiplicando, o que permite antingi-las separadamente.

  Como a iluminância é uma função de baixa variação, enquanto a reflectância é de alta frequência, é preciso utilizar um filtro passa-alta, para atenuar a iluminância. A equanção utilizada para modelar o filtro foi:

  H(u,v) = (γH − γL)(1 − e^[−c(D(u,v)²/D0²)]) + γL

  No qual os parâmetros γH e γL controlam os ganhos e atenuações das frequências altas e baixas. D(u,v) é a distância do ponto até o centro do espectro(lembrando que isso está no domínio da freqência), e D0 é a frequência de corte.

  No código, essa função é calculada da seguinte forma:

[source,cpp]
----
for(int i=0; i<dft_M; i++){
    for(int j=0; j<dft_N; j++){
      d = (i-dft_M/2)*(i-dft_M/2)+(j-dft_N/2)*(j-dft_N/2);
      tmp.at<float> (i,j) = (gamaH - gamaL)*(1 - exp(-d/(d0*d0))) + gamaL;
    }
  }
----

  Ao multiplicar esse filtro pela imagem transformada no domínio da frequência, obtemos uma atenuação das frequências baixas e um ganho nas frequências altas.

  Z(u,v) = I'(u,v) + R'(u,v)
  S(u,v) = H(u,v) * Z(u,v)
  s(x,y) = i'(x,y) + r'(x,y)

  Para "desfazer" o logaritmo aplicado anteriormente, aplicamos a exponencial dos dois lados da equação:

  g(x,y) = exp(s(x,y)) = i0'(x,y) + r0'(x,y)


  A diferença desse filtro para outros métodos de filtragem no domínio da frequência é que, antes de passar a imagem para o domínio da frequência, aplicamos o logaritmo natural:

[source,cpp]
----
log(image,image);
----

  Em seguida, é realizado o processo normal de filtragem no domínio da frequência. Aplica-se o _padding_ para adequar o tamanho da imagem para a FFT, cria-se uma matriz de zeros para ocupar a parte "imaginária" da imagem, aplica-se a transformada, inverte-se os quadrantes para maior usabilidade do espectro de frequência, aplica-se o filtro, reinverte-se os quadrantes, retorna-se ao domínio espacial e, por fim, aplicamos a exponencial(devido ao logaritmo):

[source,cpp]
----
void homo(int, void*){
  int dft_M, dft_N;
  dft_M = getOptimalDFTSize(original.rows);
  dft_N = getOptimalDFTSize(original.cols);
  image += Scalar::all(1);
  log(image,image);
  normalize(image, image, 0, 1, CV_MINMAX);
  imshow("Original", original);
  imshow("log", image);
  copyMakeBorder(image, padded, 0,
                 dft_M - image.rows, 0,
                 dft_N - image.cols,
                 BORDER_CONSTANT, Scalar::all(0));

  zeros = Mat_<float>::zeros(padded.size());
  complexImage = Mat(padded.size(), CV_32FC2, Scalar(0));
  filter = complexImage.clone();
  tmp = Mat(dft_M, dft_N, CV_32F);

  for(int i=0; i<dft_M; i++){
    for(int j=0; j<dft_N; j++){
      d = (i-dft_M/2)*(i-dft_M/2)+(j-dft_N/2)*(j-dft_N/2);
      tmp.at<float> (i,j) = (gamaH - gamaL)*(1 - exp(-d/(d0*d0))) + gamaL;
    }
  }
  Mat comps[]= {tmp, tmp};
  merge(comps, 2, filter);
  copyMakeBorder(image, padded, 0,
                   dft_M - image.rows, 0,
                   dft_N - image.cols,
                   BORDER_CONSTANT, Scalar::all(0));
  planos.clear();
  realInput = Mat_<float>(padded);
  planos.push_back(realInput);
  planos.push_back(zeros);
  merge(planos, complexImage);
  dft(complexImage, complexImage);
  deslocaDFT(complexImage);
  mulSpectrums(complexImage,filter,complexImage,0);
  planos.clear();
  deslocaDFT(complexImage);
  idft(complexImage, complexImage);
  planos.clear();
  split(complexImage, planos);
  imshow("antes da exp", planos[0]);
  //normalize(planos[0], planos[0], 0, 1, CV_MINMAX);
  exp(planos[0],final);
  normalize(final, final, 0, 1, CV_MINMAX);
  imshow("resultado", final);
}
----

Para controlar os parâmetros do filtro, foram utilizados sliders:

[source,cpp]
----
sprintf( TrackbarName, "Frequência de Corte", d0_max );
  createTrackbar( TrackbarName, "resultado",
          &d0,
          d0_max,
          homo);
  homo(d0, 0 );
  
  sprintf( TrackbarName, "gamaL", gamaL_max );
  createTrackbar( TrackbarName, "resultado",
          &gamaL,
          gamaL_max,
          homo);
  homo(gamaL, 0 );

  sprintf( TrackbarName, "gamaH", gamaH_max );
  createTrackbar( TrackbarName, "resultado",
          &gamaH,
          gamaH_max,
          homo );
  homo(gamaH, 0 );
----

Os resultados podem ser observados nas imagens:

.Original
image::teste55.png[]
.Filtrada
image::homo.png[]


=== CannyLhismo
==== Objetivo

A ideia é combinar o algoritmo de detecção de bordas de Canny e o algoritmo de pontilhismo(dado como exemplo) para criar transformar imagens comuns em obras de arte. A utilização das bordas serve para acrescentar a estética da imagem pontilhista criada. Como ambos os algoritmos foram usados como exemplos para as aplicações dos conceitos estudados em sala e, consequentimente, já devidamente explicados, a explicação a seguir irá focar mais na forma como os dois códigos foram integrados

==== Código

[source,cpp]
.canypont.cpp
----
include::cannypont.cpp[]
----

==== Análise

O código é iniciado abrindo a imagem, e em seguida transformando-a em uma imagem pontilhista. De forma simplificada, o algoritmo varre a imagem de região em região(cujas dimensões são definidas anteriormente), escolhe aleatórioamente o um dos pixels dessa região e, em seguida, atribui o valor dele aos outros píxels que formam um circulo concêntrico com a região. Isso provoca o efeito pontilhista, como se a imagem tivesse sido pintada não de forma continua, mas com "pontadas":

[source,cpp]
----

  image= imread(argv[1],CV_LOAD_IMAGE_GRAYSCALE);

  srand(time(0));
  
  if(!image.data){
  cout << "nao abriu" << argv[1] << endl;
    cout << argv[0] << " imagem.jpg";
    exit(0);
  }

  width=image.size().width;
  height=image.size().height;

  xrange.resize(height/STEP);
  yrange.resize(width/STEP);
  
  iota(xrange.begin(), xrange.end(), 0); 
  iota(yrange.begin(), yrange.end(), 0);

  for(uint i=0; i<xrange.size(); i++){
    xrange[i]= xrange[i]*STEP+STEP/2;
  }

  for(uint i=0; i<yrange.size(); i++){
    yrange[i]= yrange[i]*STEP+STEP/2;
  }

  points = Mat(height, width, CV_8U, Scalar(255));

  random_shuffle(xrange.begin(), xrange.end());
  
  for(auto i : xrange){
    random_shuffle(yrange.begin(), yrange.end());
    for(auto j : yrange){
      x = i+rand()%(2*JITTER)-JITTER+1;
      y = j+rand()%(2*JITTER)-JITTER+1;
      gray = image.at<uchar>(x,y);
      circle(points,
             cv::Point(y,x),
             RAIO,
             CV_RGB(gray,gray,gray),
             -1,
             CV_AA);
    }
  }
----
Para que o usuário poça controlar os parâmetros do algoritmo de Canny(a sensibilade do que é considerado "linha"), foi utilizado um slider:

[source,cpp]
----
namedWindow("cannypont",1);
  createTrackbar( TrackbarName, "canny",&top_slider,top_slider_max,on_trackbar_canny );
  on_trackbar_canny(top_slider, 0 );
----


Já como a imagem "convertida" para a forma pontilhista, utiliza-se a função _cannypont_. Nela, é chamada a função _Canny_, já desenvolvida na blibioteca OpenCV, que encontra as bordas da imagem passada como parâmetro:

[source,cpp]
----
void cannypont(int, void*){
  Canny(aux, border, top_slider, 3*top_slider);
----

Agora que tanto a imagem pontilhista quanto a matriz de bordas já foram calculada, é realizada a soma das duas(ponderada para que as bordas não suprimam o efeito pontilhista):

[source,cpp]
----
final = 0.8 * aux + 0.2 * border;
----

Por fim, a imagem é exibida:

.Original
image::torre.jpg[]
.Pontilhista
image::pontos.jpg[]
.CannyPont
image::canny1.jpg[]


